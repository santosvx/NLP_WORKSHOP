{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                @VirginAmerica What @dhepburn said.\n",
       "1  @VirginAmerica plus you've added commercials t...\n",
       "2  @VirginAmerica I didn't today... Must mean I n..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextBlob: An Introduction of Methods\n",
    "# Installation\n",
    "# To install TextBlob, open a new Terminal and enter the following:\n",
    "\n",
    "# Terminal\n",
    "# $ pip install -U textblob\n",
    "# $ python3 -m textblob.download_corpora\n",
    "\n",
    "# Getting Started\n",
    "#From here on, you can follow along with the notebook and create new notes and try out code as you like.\n",
    "\n",
    "# import what we need\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF, Series\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# read data\n",
    "\n",
    "# use only the column called 'text'\n",
    "data = pd.read_csv('tweets.csv', usecols=['text'])\n",
    "\n",
    "data.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextBlob object\n",
    "# TextBlob objects are the foundation of everything we will be doing. They take a string as an input and create an object on which we can apply many of the TextBlob methods.\n",
    "\n",
    "# Let's create a blob using a tweet in our data.\n",
    "\n",
    "# create a blob from the tweet at index 25\n",
    "tweet = data.text[25]\n",
    "\n",
    "blob = TextBlob(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"@VirginAmerica status match program.\"),\n",
       " Sentence(\"I applied and it's been three weeks.\"),\n",
       " Sentence(\"Called and emailed with no response.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextBlob Methods: Tokenization\n",
    "# Tokenization allows us to split a string (a paragraph, a page, etc.) into various \"tokens\" that become useful in further processing and analysis. Tokenization also occurs on the back-end of some methods.\n",
    "\n",
    "# Let's look at some tokenization options.\n",
    "\n",
    "# Sentences\n",
    "# Using the sentences method we get a list of Sentence objects, each containing (in order) all of the sentences that make up the string passed to TextBlob.\n",
    "\n",
    "# return list of Sentence objects\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Called', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('emailed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('response', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar to TextBlob objects, we can use various methods with Sentence objects.\n",
    "\n",
    "# get the first sentence\n",
    "s = blob.sentences[2]\n",
    "# get tags from this sentence\n",
    "s.tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['VirginAmerica', 'status', 'match', 'program', 'I', 'applied', 'and', 'it', \"'s\", 'been', 'three', 'weeks', 'Called', 'and', 'emailed', 'with', 'no', 'response'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words\n",
    "# Instead of a list of sentences, we can get a WordList object that returns all of the individual words in our string.\n",
    "\n",
    "# return WordList object (works like a standard list in Python)\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['it', \"'s\"])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access words in a WordList just like a regular Python list:\n",
    "blob.words[7:9]\n",
    "\n",
    "# Notice: TextBlob doesn't do the best job of handling contractions and possessive forms. Ex: \"it's\" is split into \"it\" and \"'s\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'virginamerica': 1,\n",
       "             'status': 1,\n",
       "             'match': 1,\n",
       "             'program': 1,\n",
       "             'i': 1,\n",
       "             'applied': 1,\n",
       "             'and': 2,\n",
       "             'it': 1,\n",
       "             's': 1,\n",
       "             'been': 1,\n",
       "             'three': 1,\n",
       "             'weeks': 1,\n",
       "             'called': 1,\n",
       "             'emailed': 1,\n",
       "             'with': 1,\n",
       "             'no': 1,\n",
       "             'response': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Counts\n",
    "# We can get a dict that contains all the unique words in our string as keys, and counts for each as values.\n",
    "\n",
    "# returns defaultdict with unique words as keys and counts as values.\n",
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# we can get counts for individual words is two ways\n",
    "# 1. use the count method on a WordList\n",
    "print(blob.words.count('and'))\n",
    "# 2. access a key in the word_counts dict\n",
    "print(blob.word_counts['and'])\n",
    "\n",
    "# NOTE!\n",
    "# if you use word_counts['some_word'] and that word is not originally in the defaultdict, it will be added with a count of zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'string': 1, 'of': 1, 'words': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of above\n",
    "b = TextBlob('a string of words')\n",
    "b.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count of word not in dict\n",
    "b.word_counts['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'string': 1, 'of': 1, 'words': 1, 'test': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at contents of dict again\n",
    "# notice that 'test' is now included\n",
    "b.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"@VirginAmerica status match program.\"),\n",
       " Sentence(\"I applied and it's been three weeks.\"),\n",
       " Sentence(\"Called and emailed with no response.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noun Phrases\n",
    "# Noun phrases: a word or group of words that functions in a sentence as subject, object, or prepositional object.\n",
    "\n",
    "# Examples of noun phrases are underlined in the sentences below. The head noun appears in bold.\n",
    "\n",
    "# The election-year politics are annoying for many people.\n",
    "# Almost every sentence contains at least one noun phrase.\n",
    "# Current economic weakness may be a result of high energy prices.\n",
    "# Noun phrases can be identified by the possibility of pronoun substitution, as is illustrated in the examples below.\n",
    "\n",
    "# a. This sentence contains two noun phrases.\n",
    "# b. It contains them.\n",
    "\n",
    "# We can get a WordList containing noun phrases using the noun_phrase method on a blob.\n",
    "\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['virginamerica', 'pretty graphics', 'minimal iconography'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return WordList with noun phrases for tweet at index 11\n",
    "TextBlob(data.text[11]).noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 'NN'),\n",
       " ('VirginAmerica', 'NNP'),\n",
       " ('status', 'NN'),\n",
       " ('match', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('applied', 'VBD'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('three', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('Called', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('emailed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('response', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextBlob Methods: POS & Morphology\n",
    "# Here we will cover all of the following:\n",
    "\n",
    "# part-of-speech (POS) tagging: get list of tuples containing each word and it’s part of speech (e.g. noun)\n",
    "# pluralization: get the plural form of any singular words\n",
    "# singularization: get the singular form of any plural words\n",
    "# lemmatization: get the stripped/unmodified version of a word (e.g. singing -> sing)\n",
    "\n",
    "# part-of-speech (POS) tagging\n",
    "# Using the tags method, we can get a list of doubles that contains every word in our string paired with its part of speech, as determined by the algorithm.\n",
    "\n",
    "# POS tagging (also grammatical tagging) is useful for understanding context and grammar. Many words can belong to different parts of speech, depending on the context and words around them. POS tagging attempts to disambiguate a text by determining most likely parts of speech for each word based on the content.\n",
    "\n",
    "# return list of tuples containing words in a string and the part of speech that each belongs to\n",
    "blob.tags\n",
    "\n",
    "# The tags each have a unique meaning. For example:\n",
    "\n",
    "# 'VBX': verb (X indicates type of verb)\n",
    "# 'DT': determiner\n",
    "# A comprehensive table can be found at http://www.clips.ua.ac.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'companies'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pluralization\n",
    "# This is a relatively simple rule-based process that takes the singular form of a word and applies the correct pluralization to it.\n",
    "\n",
    "# In TextBlob we can pluralize a single word (in the form of a Word obj.) or pluralize all words in a WordList.\n",
    "\n",
    "# import\n",
    "from textblob import Word, WordList\n",
    "# create a Word object\n",
    "w = Word('company')\n",
    "# return the plural of a single word\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['who', 'what', 'when', 'where', 'why'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Side note: we can also create WordList objects\n",
    "wl = WordList(['who','what','when','where','why'])\n",
    "wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['agency', 'octopus', 'word'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# singularization\n",
    "# The opposite of pluralization: take a word (or words) in plural form and singularize them.\n",
    "\n",
    "wl = WordList(['agencies', 'octopi', 'words'])\n",
    "wl.singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "# Lemmatization takes a word that has been modified or morphed in some way using proper linguistic rules, and returns the stripped/unmodified version of it.\n",
    "\n",
    "# The lemmatize() method has an optional parameter:\n",
    "\n",
    "# pos – Part of speech to filter upon. If None, defaults to _wordnet.NOUN.\n",
    "# options:\n",
    "# 'n' for noun,\n",
    "# 'v' for verb,\n",
    "# 'a' for adjective,\n",
    "# 'r' for adverb.\n",
    "# Note: adverbs don't usually work with the standard lemmatize method.\n",
    "\n",
    "w = Word('singing')\n",
    "# for some words you have to pass the type\n",
    "# in this case we pass 'v' for verb (not to be confused with POS tag formats)\n",
    "w.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# past participle verb\n",
    "w = Word('went')\n",
    "w.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kindly'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it doesn't always work: try an adverb\n",
    "w = Word('kindly')\n",
    "w.lemmatize('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John/NNP/B-NP/O loves/VBZ/B-VP/O Mary/NNP/B-NP/O'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing & n-grams\n",
    "# Parsing\n",
    "# Parsing gives us the syntactic structure of a string or sentence by appending each word with tags that indicate it's place in a hierarchy. See the tree in the PowerPoint slides for a visual example.\n",
    "\n",
    "# Let's parse the sentence shown in the tree:\n",
    "\n",
    "# return a string containing each word in the text along with its parts of speech hierarchy\n",
    "b = TextBlob('John loves Mary')\n",
    "b.parse()\n",
    "\n",
    "# John/NNP/B-NP/O gives the position in the hierarchy of the text for the word \"John\" in our sentence, working from the word to the top of the hierarchy.\n",
    "\n",
    "# In this case (For the word John):\n",
    "\n",
    "# NNP indicates it is a \"noun, proper singular\"\n",
    "# the B- in B-NP indicates the word is: inside the chunk, preceding word is part of a different chunk\n",
    "# the NP in B-NP indicates it is part of a noun phrase\n",
    "# O is \"not part of chunk\", meaning we are at the end of this particular hierarchy (chunk).\n",
    "# Details can be read on the page that gives detailed parts of speech (link posted under POS tagging).\n",
    "\n",
    "# Parsing and syntactic structure is a complex subject, and is not covered in depth here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['VirginAmerica', 'status', 'match']),\n",
       " WordList(['status', 'match', 'program']),\n",
       " WordList(['match', 'program', 'I']),\n",
       " WordList(['program', 'I', 'applied']),\n",
       " WordList(['I', 'applied', 'and'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# n-grams are groups of n successive words. Quite often n-grams are created by shifting one word at a time through a text, but there are cases where they skip k-words at a time.\n",
    "\n",
    "# The usefulness of n-grams comes in with machine learning, where each n-gram is used as a feature for learning. These will be used more in the next workshop, but for now let's look at getting n-grams from a text using TextBlob:\n",
    "\n",
    "# TextBlob has an ngrams method that will take an optional argument n, which is the size of n-grams to generate. Default is 3.\n",
    "\n",
    "# The method returns a list of WordList objects.\n",
    "\n",
    "# return list of n-grams (default n=3)\n",
    "# get only first 5 n-grams\n",
    "blob.ngrams()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['VirginAmerica', 'status']),\n",
       " WordList(['status', 'match']),\n",
       " WordList(['match', 'program']),\n",
       " WordList(['program', 'I']),\n",
       " WordList(['I', 'applied'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get another set with n = 2\n",
    "blob.ngrams(n=2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
